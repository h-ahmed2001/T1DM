{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db01f066-cf01-45b9-8ede-88d2ca7b0552",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7e622b97-b731-4ed1-9477-b444ac12dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9150d3f8-ab0b-4b98-985c-1c0a16756140",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8fb97128-a6b3-4484-8a64-7f59096518c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataframe\n",
    "df_train = pd.read_csv('path-to-file-train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b335ee-d4f6-4f24-ab6e-6ec31b41bfea",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e596cf-d1b2-4992-949c-40a3689525f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduce lag features\n",
    "df_train['glucose_lag30'] = df_train['glucose'].shift(6)\n",
    "df_train['carbs_lag30'] = df_train['carbs'].shift(6)\n",
    "df_train['bolus_dose_lag30'] = df_train['bolus_dose'].shift(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3ad2d99c-e52c-4fe0-8fbe-f71993fc36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocess function\n",
    "def preprocess_data(df):\n",
    "    # Convert timestamp to date time \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "\n",
    "    # Sort by timestamp to maintain proper sequence\n",
    "    df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "   \n",
    "    # Scaling the features using standard scaling\n",
    "    scaler = StandardScaler()\n",
    "    df[['glucose', 'basal_rate', 'bolus_dose', 'carbs', 'glucose_lag30', 'carbs_lag30', 'bolus_dose_lag30']] = \\\n",
    "    scaler.fit_transform(df[['glucose', 'basal_rate', 'bolus_dose', 'carbs', 'glucose_lag30', 'carbs_lag30', 'bolus_dose_lag30']])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "094aa39b-8ffa-47a5-9886-ddf2fd9961b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "df_train_processed = preprocess_data(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2150e6fb-f1b8-4612-877c-0028309da8ad",
   "metadata": {},
   "source": [
    "### Extended Kalman Filter Model Development/Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14526496-bab0-4f2b-a048-ae724a801030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EKF parameters\n",
    "x = np.array([30.0])  # Initial ISF estimate, use a value within normal range (30-50)\n",
    "P = np.array([[0.1]])  # Initial covariance matrix, represents the uncertainty in ISF estimate\n",
    "Q = np.array([[0.05]])  # Process noise, controls the extent of state change between time steps\n",
    "R = np.array([[0.01]])  # Measurement noise, controls the noise in glucose measurements\n",
    "\n",
    "# Prepare feature matrix 'u', for the state transition and measurement models\n",
    "u = np.zeros((df_train_processed.shape[0], 6))    # Create a zero-filled matrix with 6 columns for the features\n",
    "u[:, 0] = df_train_processed['glucose']\n",
    "u[:, 1] = df_train_processed['basal_rate']\n",
    "u[:, 2] = df_train_processed['bolus_dose']\n",
    "u[:, 3] = df_train_processed['carbs']\n",
    "u[:, 4] = df_train_processed['glucose_lag30']\n",
    "u[:, 5] = df_train_processed['carbs_lag30']   \n",
    "\n",
    "# Define the nonlinear state transition function\n",
    "def nonlinear_state_transition(x, u):\n",
    "    \n",
    "    # Unpack the input features (u)\n",
    "    glucose, basal_rate, bolus_dose, carbs, glucose_lag30, carbs_lag30 = u\n",
    "\n",
    "    # Estimate the effects of bolus insulin, carbohydrates, and basal insulin on ISF\n",
    "    bolus_effect = 0.001 * (bolus_dose - 0.5)  # Bolus insulin effect on ISF\n",
    "    carbs_effect = -0.001 * carbs   # Carbohydrate effect \n",
    "    basal_effect = 0.001 * basal_rate   # Basal insulin effect\n",
    "    \n",
    "    # Predict the next state (ISF) by adding the effects to the current ISF\n",
    "    x_pred = x + bolus_effect + carbs_effect + basal_effect\n",
    "    \n",
    "    return x_pred  # Return the predicted ISF\n",
    "\n",
    "# Define the nonlinear measurement model to predict glucose levels\n",
    "def nonlinear_measurement_model(x, u, params):\n",
    "    \n",
    "    # Unpack the input features (u)\n",
    "    glucose, basal_rate, bolus_dose, carbs, glucose_lag30, carbs_lag30 = u\n",
    "    \n",
    "     # Unpack additional parameters (e.g., weights for lagged features)\n",
    "    lag_weight_glucose, lag_weight_carbs = params        \n",
    "    \n",
    "     # Estimate the predicted glucose using ISF, insulin (basal + bolus), and carb intake\n",
    "    z_pred = glucose - (\n",
    "        x[0] * (0.5 * basal_rate + 0.6 * bolus_dose + 0.4 * carbs) + \n",
    "        lag_weight_glucose * glucose_lag30 +  # Influence of lagged glucose\n",
    "        lag_weight_carbs * carbs_lag30        # Influence of lagged carbs\n",
    "    )\n",
    "    return z_pred         # Return the predicted glucose value\n",
    "\n",
    "\n",
    "# EKF Prediction Step (this predicts the next state and uncertainty)\n",
    "def predict(x, P, u, Q):\n",
    "    \n",
    "    F = np.array([[1]])  # Jacobian of the state transition (identity because we are using linearization)\n",
    "    \n",
    "    # Predict the next state (ISF) using the state transition function\n",
    "    x_pred = nonlinear_state_transition(x, u)\n",
    "\n",
    "    # Predict the next covariance (uncertainty in the ISF estimate)\n",
    "    P_pred = np.dot(F, np.dot(P, F.T)) + Q   # Adding process noise (Q) to the covariance\n",
    "    \n",
    "    return x_pred, P_pred  # Return the predicted state and covariance\n",
    "\n",
    "# EKF Update Step (this adjusts the state prediction based on the measurement)\n",
    "def update(x_pred, P_pred, z, u, R, params):\n",
    "    \n",
    "    H = np.array([[1]])  # Jacobian of the measurement model (identity for simplicity)\n",
    "    \n",
    "    # Predict the glucose measurement using the measurement model\n",
    "    z_pred = nonlinear_measurement_model(x_pred, u, params)\n",
    "    \n",
    "    # Calculate the residual (difference between actual and predicted glucose)\n",
    "    y = z - z_pred  # This is the innovation (residual) term\n",
    "    \n",
    "     # Calculate the innovation covariance (S) and add measurement noise (R)\n",
    "    S = np.dot(H, np.dot(P_pred, H.T)) + R\n",
    "    \n",
    "     # Regularize S if it's near zero (to avoid numerical instability)\n",
    "    if np.linalg.det(S) == 0 or np.abs(np.linalg.det(S)) < 1e-6:\n",
    "        S += 1e-6  # Add a small value to ensure it's invertible\n",
    "    \n",
    "    # Kalman Gain calculation: determines how much to adjust the state estimate\n",
    "    K = np.dot(P_pred, np.dot(H.T, np.linalg.inv(S)))\n",
    "    \n",
    "    # Update the state estimate with the Kalman Gain and residual\n",
    "    x_updated = np.clip(x_pred + np.dot(K, y), 20, 60)  # Keep ISF within reasonable bounds\n",
    "    \n",
    "    # Update the covariance matrix (reducing uncertainty after incorporating the measurement)\n",
    "    P_updated = P_pred - np.dot(K, np.dot(H, P_pred))\n",
    "    \n",
    "    return x_updated, P_updated  # Return the updated state and covariance\n",
    "\n",
    "# Initialize a list to store ISF estimates over time\n",
    "isf_estimates = []\n",
    "\n",
    "# Define parameters (weights) for lagged features\n",
    "params = (0.5, 0.7) \n",
    "\n",
    "# Skip the first hour of predictions \n",
    "skip_steps = 12  # 12 steps for 5-minute intervals\n",
    "\n",
    "# Loop through the dataset starting from the time index after the skipped steps\n",
    "for t in range(skip_steps, len(df_train_processed)):\n",
    "\n",
    "    # Get the current glucose measurement (z)\n",
    "    z = np.array([df_train_processed['glucose'].iloc[t]])\n",
    "\n",
    "    # Predict the next state (ISF) and covariance\n",
    "    x_pred, P_pred = predict(x, P, u[t, :], Q)\n",
    "\n",
    "    # Update the state estimate based on the actual glucose measurement\n",
    "    x, P = update(x_pred, P_pred, z, u[t, :], R, params)\n",
    "    \n",
    "    # Handle any overflow or NaN values (if the model produces invalid results)\n",
    "    if np.any(np.isinf(x)) or np.any(np.isnan(x)):\n",
    "        print(f\"Warning: Overflow or NaN detected at time index {t}\")\n",
    "\n",
    "    # Append the updated ISF estimate to the list\n",
    "    isf_estimates.append(x[0])\n",
    "    \n",
    "# Fill the skipped steps with NaN to align the time index\n",
    "isf_estimates = [np.nan] * skip_steps + isf_estimates\n",
    "\n",
    "# Add the ISF predictions to the processed dataframe\n",
    "df_train_processed['isf_predictions'] = isf_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d79be1b-b229-4b02-8830-2a0a5172935b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12396.000000\n",
       "mean        39.887879\n",
       "std         19.478007\n",
       "min         20.000000\n",
       "25%         20.000000\n",
       "50%         35.492992\n",
       "75%         60.000000\n",
       "max         60.000000\n",
       "Name: isf_predictions, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a sample of the results, skipping the 1st hour\n",
    "df_train_processed[['timestamp', 'isf_predictions']].iloc[11:26]\n",
    "\n",
    "# Examine distribution of predictions\n",
    "df_train_processed['isf_predictions'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ca80d4-a71c-49bb-a3af-88ebd677a2ed",
   "metadata": {},
   "source": [
    "### Model Testing and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "b3991e4c-15b8-4fe0-b64f-9d71ff70fb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataframe\n",
    "df_test = pd.read_csv('path-to-file-test.csv')\n",
    "\n",
    "# Introduce lag features\n",
    "df_test['glucose_lag30'] = df_test['glucose'].shift(6)\n",
    "df_test['carbs_lag30'] = df_test['carbs'].shift(6)\n",
    "df_test['bolus_dose_lag30'] = df_test['bolus_dose'].shift(6)\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d14a5-0b66-4a7c-9295-d5e4e376c93f",
   "metadata": {},
   "source": [
    "### Calculate ISF using 1700 Rule (ISF = 1700/Total Daily Dose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "7b7e3adf-e788-493c-a4a6-8451e1d0afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime if not already\n",
    "df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
    "\n",
    "# Set timestamp as index\n",
    "df_test.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "de8d34b1-5061-4864-ac8a-2c38a9c73026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to daily intervals and calculate the sum of basal insulin doses\n",
    "df_daily_basals = df_test.resample('D').agg({\n",
    "    'basal_rate': 'mean',  # Average basal rate for the day\n",
    "    'bolus_dose': 'sum'    # Total bolus dose for the day\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate total daily insulin dose (TDD) for each day\n",
    "df_daily_basals['total_insulin_dose'] = df_daily_basals['basal_rate'] * 24 + df_daily_basals['bolus_dose']  # Assuming basal_rate is in units per hour\n",
    "\n",
    "# Compute ISF using the 1700 rule\n",
    "df_daily_basals['isf_1700'] = 1700 / df_daily_basals['total_insulin_dose'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120170c-718e-4543-92f2-c7e82e4a27cd",
   "metadata": {},
   "source": [
    "### Predict ISF using EKF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d402391a-6508-4b44-a4fa-c9b8a8a0b830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataframe\n",
    "df_test = pd.read_csv('path-to-file-test.csv')\n",
    "\n",
    "# Introduce lag features\n",
    "df_test['glucose_lag30'] = df_test['glucose'].shift(6)\n",
    "df_test['carbs_lag30'] = df_test['carbs'].shift(6)\n",
    "df_test['bolus_dose_lag30'] = df_test['bolus_dose'].shift(6)\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "b9edcbaa-8df0-424d-a93a-3e5553715403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing and save the scaler\n",
    "df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
    "df_test_processed = preprocess_data(df_test)\n",
    "\n",
    "# Initialize EKF parameters\n",
    "x = np.array([30.0])  \n",
    "P = np.array([[0.1]]) \n",
    "Q = np.array([[0.05]]) \n",
    "R = np.array([[0.01]])  \n",
    "\n",
    "# Adjust the shape of u to include all necessary features\n",
    "u = np.zeros((df_test_processed.shape[0], 6))  # Now with 6 columns\n",
    "u[:, 0] = df_test_processed['glucose']\n",
    "u[:, 1] = df_test_processed['basal_rate']\n",
    "u[:, 2] = df_test_processed['bolus_dose']\n",
    "u[:, 3] = df_test_processed['carbs']\n",
    "u[:, 4] = df_test_processed['glucose_lag30']  # Use 30-minute lag\n",
    "u[:, 5] = df_test_processed['carbs_lag30']    # Use 30-minute lag\n",
    "\n",
    "# Initialize a list to store ISF estimates over time\n",
    "isf_estimates = []\n",
    "\n",
    "# Define parameters (weights) for lagged features\n",
    "params = (0.5, 0.7)\n",
    "\n",
    "# Skip the first hour of predictions \n",
    "skip_steps = 12  # 12 steps for 5-minute intervals\n",
    "\n",
    "# Loop through the dataset starting from the time index after the skipped steps\n",
    "for t in range(skip_steps, len(df_test_processed)):\n",
    "    \n",
    "    # Get the current glucose measurement (z)\n",
    "    z = np.array([df_test_processed['glucose'].iloc[t]])\n",
    "\n",
    "    # Predict the next state (ISF) and covariance\n",
    "    x_pred, P_pred = predict(x, P, u[t, :], Q)\n",
    "\n",
    "    # Update the state estimate based on the actual glucose measurement\n",
    "    x, P = update(x_pred, P_pred, z, u[t, :], R, params)\n",
    "    \n",
    "    # Handle any overflow or NaN values (if the model produces invalid results)\n",
    "    if np.any(np.isinf(x)) or np.any(np.isnan(x)):\n",
    "        print(f\"Warning: Overflow or NaN detected in state update at time index {t}\")\n",
    "\n",
    "    # Append the updated ISF estimate to the list\n",
    "    isf_estimates.append(x[0])\n",
    "\n",
    "# Fill the skipped steps with NaN to align the time index\n",
    "isf_estimates = [np.nan] * skip_steps + isf_estimates\n",
    "\n",
    "# Add the ISF predictions to the processed dataframe\n",
    "df_test_processed['isf_predictions'] = isf_estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aa3041-758a-4420-85b4-ea7b83bc3ea4",
   "metadata": {},
   "source": [
    "##### Aggregate EKF-ISF results into hourly estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415614b1-9d46-400c-aa50-a2e165c84b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'timestamp' is already in datetime format \n",
    "df_test_processed['timestamp'] = pd.to_datetime(df_test_processed['timestamp'])\n",
    "\n",
    "# Set the timestamp as the DataFrame index (if not already)\n",
    "df_test_processed.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Resample to hourly intervals and take the mean of 'isf_predictions' for each hour\n",
    "df_hourly_isf = df_test_processed['isf_predictions'].resample('H').mean()\n",
    "\n",
    "# Reset index to get the 'timestamp' back as a column\n",
    "df_hourly_isf = df_hourly_isf.reset_index()\n",
    "\n",
    "# Now df_hourly_isf contains hourly timestamp and averaged ISF predictions\n",
    "#df_hourly_isf.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e28eb5-9c61-47e6-8efb-fb202dabc9a9",
   "metadata": {},
   "source": [
    "### Combine the EKF-ISF and 1700-ISF values into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cbb684-fe9d-4201-a04f-5d00d2a0e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the timestamp in df_daily_basals to datetime\n",
    "df_daily_basals['timestamp'] = pd.to_datetime(df_daily_basals['timestamp'])\n",
    "\n",
    "# Resample the 'isf_1700' column from df_daily_basals to match the hourly timestamps in df_hourly_isf\n",
    "# Use the timestamps in df_hourly_isf as the reference for the resampling\n",
    "df_daily_basals_resampled = df_daily_basals.set_index('timestamp')['isf_1700'].reindex(df_hourly_isf['timestamp'], method='ffill')\n",
    "\n",
    "# Combine df_hourly_isf with the resampled df_daily_basals\n",
    "df_hourly_isf['isf_1700'] = df_daily_basals_resampled.values\n",
    "\n",
    "# Keep only the 'timestamp', 'isf_predictions', and 'isf_1700' columns\n",
    "df_combined = df_hourly_isf[['timestamp', 'isf_predictions', 'isf_1700']]\n",
    "\n",
    "# Drop first value\n",
    "df_combined = df_combined.drop(df_combined.index[0])\n",
    "\n",
    "# Display the combined DataFrame\n",
    "df_combined.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318cc07b-e960-42c9-aa6c-01b36a9318f5",
   "metadata": {},
   "source": [
    "### Evaluate results, by checking expected glucose values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "50df9f72-863d-4302-8e17-6420a122d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataframe\n",
    "df_test = pd.read_csv('path-to-file-test.csv')\n",
    "\n",
    "# Introduce lag features\n",
    "df_test['glucose_lag30'] = df_test['glucose'].shift(6)\n",
    "df_test['carbs_lag30'] = df_test['carbs'].shift(6)\n",
    "df_test['bolus_dose_lag30'] = df_test['bolus_dose'].shift(6)\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87092021-c425-4751-9a0f-d99446d17500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Define a more complex function to simulate expected glucose levels with delayed insulin effect\n",
    "def calculate_expected_glucose_after_delay(isf, current_glucose, bolus_dose, carbs, \n",
    "                                            delay_factor=0.5, peak_time=60, decay_rate=0.1, \n",
    "                                            carb_absorption_delay=30, individual_variability=0.05):\n",
    "   \n",
    "    # Simulate insulin effect profile with peak and decay\n",
    "    time_since_bolus = 30  # Assuming we're evaluating 30 minutes post-bolus\n",
    "    if time_since_bolus < peak_time:\n",
    "        insulin_effect = isf * bolus_dose * delay_factor * (time_since_bolus / peak_time)\n",
    "    else:\n",
    "        insulin_effect = isf * bolus_dose * delay_factor * ((1 - decay_rate) + decay_rate \n",
    "                                                            * (peak_time / time_since_bolus))\n",
    "\n",
    "    # Simulate delayed carb absorption\n",
    "    carb_effect = carbs * (1 - np.exp(-time_since_bolus / carb_absorption_delay))\n",
    "    \n",
    "    # Apply individual variability\n",
    "    variability = np.random.uniform(-individual_variability, individual_variability)\n",
    "    \n",
    "    # Simulate expected glucose considering the insulin action profile, delayed carb absorption\n",
    "    expected_glucose = current_glucose - insulin_effect + carb_effect + variability\n",
    "    \n",
    "    return expected_glucose\n",
    "\n",
    "# Ensure 'timestamp' column is in datetime format for both test and combined dataframes\n",
    "df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
    "df_combined['timestamp'] = pd.to_datetime(df_combined['timestamp'])\n",
    "\n",
    "# Set timestamp as index for df_test and resample glucose data to hourly intervals\n",
    "df_test.set_index('timestamp', inplace=True)\n",
    "df_test_hourly = df_test.resample('H').mean().reset_index()\n",
    "\n",
    "# Drop columns that are not needed for aggregation\n",
    "df_test_hourly.drop(columns=['basal_rate', 'sleep_duration_hours', 'bolus_duration_mins', \n",
    "                             'exercise_duration_mins', 'bolus_flag', 'meal_flag', \n",
    "                             'exercise_flag', 'hour_of_day'], inplace=True)\n",
    "\n",
    "# Merge df_combined with df_test_hourly to align the timestamps\n",
    "df_merged = pd.merge(df_combined, df_test_hourly, on='timestamp')\n",
    "\n",
    "# Apply the updated function to estimate glucose levels based on ISF predictions\n",
    "df_merged['expected_glucose_isf'] = df_merged.apply(lambda row: calculate_expected_glucose_after_delay(\n",
    "    row['isf_predictions'], row['glucose'], row['bolus_dose'], row['carbs']), axis=1)\n",
    "\n",
    "# Apply the updated function to estimate glucose levels based on the 1700 rule\n",
    "df_merged['expected_glucose_1700'] = df_merged.apply(lambda row: calculate_expected_glucose_after_delay(\n",
    "    row['isf_1700'], row['glucose'], row['bolus_dose'], row['carbs']), axis=1)\n",
    "\n",
    "df_merged = df_merged.dropna()\n",
    "\n",
    "# Calculate errors for ISF predictions\n",
    "mae_isf = mean_absolute_error(df_merged['glucose'], df_merged['expected_glucose_isf'])\n",
    "mse_isf = mean_squared_error(df_merged['glucose'], df_merged['expected_glucose_isf'])\n",
    "r2_isf = r2_score(df_merged['glucose'], df_merged['expected_glucose_isf'])\n",
    "\n",
    "# Calculate errors for 1700 rule\n",
    "mae_1700 = mean_absolute_error(df_merged['glucose'], df_merged['expected_glucose_1700'])\n",
    "mse_1700 = mean_squared_error(df_merged['glucose'], df_merged['expected_glucose_1700'])\n",
    "r2_1700 = r2_score(df_merged['glucose'], df_merged['expected_glucose_1700'])\n",
    "\n",
    "print(f\"MAE for ISF Predictions: {mae_isf}\")\n",
    "print(f\"MSE for ISF Predictions: {mse_isf}\")\n",
    "print(f\"R^2 for ISF Predictions: {r2_isf}\")\n",
    "\n",
    "print(f\"MAE for 1700 Rule: {mae_1700}\")\n",
    "print(f\"MSE for 1700 Rule: {mse_1700}\")\n",
    "print(f\"R^2 for 1700 Rule: {r2_1700}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
