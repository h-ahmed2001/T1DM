{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bec1ffdd-434e-4fd1-8856-aa9c7748056b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "89a8f84e-9f4e-4fdb-b9c1-a9bbc9cfae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import csv \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a957cb-6943-4670-93ac-56626a337a21",
   "metadata": {},
   "source": [
    "## Parsing XML Files into Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "757ca4bd-7a38-49b0-b7ab-31c0a9989628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(file_path):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Initialize dictionaries to hold data\n",
    "    glucose_data = []\n",
    "    bolus_data = []\n",
    "    basal_data = []\n",
    "    meal_data = []\n",
    "    finger_stick_data = []\n",
    "    temp_basal_data = []\n",
    "    sleep_data = []\n",
    "    work_data = []\n",
    "    stressors_data = []\n",
    "    hypo_event_data = []\n",
    "    illness_data = []\n",
    "    exercise_data = []\n",
    "    basis_heart_rate_data = []\n",
    "    basis_gsr_data = []\n",
    "    basis_skin_temp_data = []\n",
    "    basis_air_temp_data = []\n",
    "    basis_steps_data = []\n",
    "    basis_sleep_data = []\n",
    "    \n",
    "    # Extract glucose levels\n",
    "    for event in root.findall('.//glucose_level/event'):\n",
    "        ts = event.attrib['ts']\n",
    "        value = float(event.attrib['value'])\n",
    "        glucose_data.append({'timestamp': ts, \n",
    "                             'glucose': value})\n",
    "    \n",
    "    # Extract bolus data\n",
    "    for event in root.findall('.//bolus/event'):\n",
    "        ts_begin = event.attrib['ts_begin']\n",
    "        ts_end = event.attrib['ts_end']\n",
    "        type = event.attrib['type']\n",
    "        dose = float(event.attrib['dose'])\n",
    "        carb_input = float(event.attrib['bwz_carb_input'])\n",
    "        bolus_data.append({'ts_begin': ts_begin,\n",
    "                           'ts_end': ts_end, \n",
    "                           'type': type,\n",
    "                           'dose': dose, \n",
    "                           'carb_input': carb_input})\n",
    "    \n",
    "    # Extract basal data\n",
    "    for event in root.findall('.//basal/event'):\n",
    "        ts = event.attrib['ts']\n",
    "        value = float(event.attrib['value'])\n",
    "        basal_data.append({'timestamp': ts,\n",
    "                           'basal_rate': value})\n",
    "    \n",
    "    # Extract meal data\n",
    "    for event in root.findall('.//meal/event'):\n",
    "        ts = event.attrib['ts']\n",
    "        meal_type = event.attrib['type']\n",
    "        carbs = float(event.attrib['carbs'])\n",
    "        meal_data.append({'timestamp': ts,\n",
    "                          'meal_type': meal_type,\n",
    "                          'carbs': carbs})\n",
    "    \n",
    "    # Extract finger stick data\n",
    "    for event in root.findall('.//finger_stick/event'):\n",
    "        ts = event.attrib['ts']\n",
    "        value = float(event.attrib['value'])\n",
    "        finger_stick_data.append({'timestamp': ts, \n",
    "                                  'finger_stick': value})\n",
    "    \n",
    "    # Extract temp basal data\n",
    "    for event in root.findall('.//temp_basal/event'):\n",
    "        ts_begin = event.attrib['ts_begin']\n",
    "        ts_end = event.attrib['ts_end']\n",
    "        value = float(event.attrib['value'])\n",
    "        temp_basal_data.append({'ts_begin': ts_begin,\n",
    "                                'ts_end': ts_end,\n",
    "                                'temp_basal_rate': value})\n",
    "    \n",
    "    # Extract sleep data\n",
    "    for event in root.findall('.//sleep/event'):\n",
    "        ts_begin = event.attrib['ts_begin']\n",
    "        ts_end = event.attrib['ts_end']\n",
    "        quality = int(event.attrib['quality'])\n",
    "        sleep_data.append({'ts_begin': ts_begin,\n",
    "                           'ts_end': ts_end,\n",
    "                           'quality': quality})\n",
    "    \n",
    "    # Extract work data\n",
    "    for event in root.findall('.//work/event'):\n",
    "        ts_begin = event.attrib['ts_begin']\n",
    "        ts_end = event.attrib['ts_end']\n",
    "        intensity = int(event.attrib['intensity'])\n",
    "        work_data.append({'ts_begin': ts_begin, \n",
    "                          'ts_end': ts_end,\n",
    "                          'intensity': intensity})\n",
    "    \n",
    "    # Extract stressors data\n",
    "    for event in root.findall('.//stressors/event'):\n",
    "        ts = event.attrib['ts']\n",
    "        stress_type = event.attrib['type']\n",
    "        description = event.attrib['description']\n",
    "        stressors_data.append({'timestamp': ts, \n",
    "                               'type': stress_type,\n",
    "                               'description': description})\n",
    "    \n",
    "    # Extract hypo event data\n",
    "    for event in root.findall('.//hypo_event/event'):\n",
    "        ts = event.attrib['ts']\n",
    "        symptom_name = event.find('symptom').attrib['name']\n",
    "        hypo_event_data.append({'timestamp': ts, \n",
    "                                'symptom_name': symptom_name})\n",
    "    \n",
    "    # Extract illness data\n",
    "    for event in root.findall('.//illness/event'):\n",
    "        ts_begin = event.attrib['ts_begin']\n",
    "        ts_end = event.attrib['ts_end']\n",
    "        illness_type = event.attrib['type']\n",
    "        description = event.attrib['description']\n",
    "        illness_data.append({'ts_begin': ts_begin,\n",
    "                             'ts_end': ts_end,\n",
    "                             'type': illness_type, \n",
    "                             'description': description})\n",
    "    \n",
    "    # Extract exercise data\n",
    "    for event in root.findall('.//exercise/event'):\n",
    "        ts = event.attrib['ts']\n",
    "        intensity = int(event.attrib['intensity'])\n",
    "        exercise_type = event.attrib['type']\n",
    "        duration = int(event.attrib['duration'])\n",
    "        competitive = event.attrib['competitive']\n",
    "        exercise_data.append({'timestamp': ts, \n",
    "                              'intensity': intensity, \n",
    "                              'type': exercise_type,\n",
    "                              'duration': duration, \n",
    "                              'competitive': competitive})\n",
    "    \n",
    "    # Extract basis heart rate data\n",
    "    for event in root.findall('.//basis_heart_rate/event'):\n",
    "        ts = event.attrib['ts']\n",
    "        value = int(event.attrib['value'])\n",
    "        basis_heart_rate_data.append({'timestamp': ts,\n",
    "                                      'heart_rate': value})\n",
    "    \n",
    "    # Extract basis GSR data\n",
    "    for event in root.findall('.//basis_gsr/event'):\n",
    "        ts = event.attrib['ts']\n",
    "        value = float(event.attrib['value'])\n",
    "        basis_gsr_data.append({'timestamp': ts, \n",
    "                               'gsr': value})\n",
    "    \n",
    "    # Extract basis skin temperature data\n",
    "    for event in root.findall('.//basis_skin_temperature/event'):\n",
    "        ts = event.attrib['ts']\n",
    "        value = float(event.attrib['value'])\n",
    "        basis_skin_temp_data.append({'timestamp': ts, \n",
    "                                     'skin_temp': value})\n",
    "    \n",
    "    # Extract basis air temperature data\n",
    "    for event in root.findall('.//basis_air_temperature/event'):\n",
    "        ts = event.attrib['ts']\n",
    "        value = float(event.attrib['value'])\n",
    "        basis_air_temp_data.append({'timestamp': ts,\n",
    "                                    'air_temp': value})\n",
    "    \n",
    "    # Extract basis steps data\n",
    "    for event in root.findall('.//basis_steps/event'):\n",
    "        ts = event.attrib['ts']\n",
    "        value = int(event.attrib['value'])\n",
    "        basis_steps_data.append({'timestamp': ts,\n",
    "                                 'steps': value})\n",
    "    \n",
    "    # Extract basis sleep data\n",
    "    for event in root.findall('.//basis_sleep/event'):\n",
    "        tbegin = event.attrib['tbegin']\n",
    "        tend = event.attrib['tend']\n",
    "        quality = int(event.attrib['quality'])\n",
    "        sleep_type = event.attrib['type']\n",
    "        basis_sleep_data.append({'tbegin': tbegin, \n",
    "                                 'tend': tend,\n",
    "                                 'quality': quality,\n",
    "                                 'type': sleep_type})\n",
    "    \n",
    "    # Convert to pandas DataFrames\n",
    "    df_glucose = pd.DataFrame(glucose_data)\n",
    "    df_bolus = pd.DataFrame(bolus_data)\n",
    "    df_basal = pd.DataFrame(basal_data)\n",
    "    df_meal = pd.DataFrame(meal_data)\n",
    "    df_finger_stick = pd.DataFrame(finger_stick_data)\n",
    "    df_temp_basal = pd.DataFrame(temp_basal_data)\n",
    "    df_sleep = pd.DataFrame(sleep_data)\n",
    "    df_work = pd.DataFrame(work_data)\n",
    "    df_stressors = pd.DataFrame(stressors_data)\n",
    "    df_hypo_event = pd.DataFrame(hypo_event_data)\n",
    "    df_illness = pd.DataFrame(illness_data)\n",
    "    df_exercise = pd.DataFrame(exercise_data)\n",
    "    df_basis_heart_rate = pd.DataFrame(basis_heart_rate_data)\n",
    "    df_basis_gsr = pd.DataFrame(basis_gsr_data)\n",
    "    df_basis_skin_temp = pd.DataFrame(basis_skin_temp_data)\n",
    "    df_basis_air_temp = pd.DataFrame(basis_air_temp_data)\n",
    "    df_basis_steps = pd.DataFrame(basis_steps_data)\n",
    "    df_basis_sleep = pd.DataFrame(basis_sleep_data)\n",
    "    \n",
    "    # Return DataFrames directly\n",
    "    return df_glucose, df_bolus, df_basal, df_meal, df_finger_stick, df_temp_basal, df_sleep, df_work,\n",
    "    df_stressors, df_hypo_event, df_illness, df_exercise, df_basis_heart_rate, df_basis_gsr, \n",
    "    df_basis_skin_temp, df_basis_air_temp, df_basis_steps, df_basis_sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "957ce0b2-8a8b-43c5-8e25-abded65e8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your XML file\n",
    "file_path = 'path-to-file.xml'\n",
    "\n",
    "# Parse the XML and extract data into DataFrames\n",
    "train_data = parse_xml(file_path)\n",
    "\n",
    "# Unpack the DataFrames\n",
    "df_glucose, df_bolus, df_basal, df_meal, df_finger_stick, df_temp_basal, df_sleep, df_work,\n",
    "df_stressors, df_hypo_event, df_illness, df_exercise, df_basis_heart_rate, df_basis_gsr, \n",
    "df_basis_skin_temp, df_basis_air_temp, df_basis_steps, df_basis_sleep = train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a621da-1003-4d04-bfb1-34f3d6872fb3",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df07d75-2007-4313-9e96-cc56a65f43a4",
   "metadata": {},
   "source": [
    "#### 1. Convert timestamp to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6864d950-6410-4499-940c-ca39ba0b8a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples containing the dataframe and column name\n",
    "datetime_columns = [\n",
    "    (df_glucose, 'timestamp'),\n",
    "    (df_bolus, 'ts_begin'),\n",
    "    (df_bolus, 'ts_end'),\n",
    "    (df_basal, 'timestamp'),\n",
    "    (df_meal, 'timestamp'),\n",
    "    (df_finger_stick, 'timestamp'),\n",
    "    (df_temp_basal, 'ts_begin'),\n",
    "    (df_temp_basal, 'ts_end'),\n",
    "    (df_sleep, 'ts_begin'),\n",
    "    (df_sleep, 'ts_end'),\n",
    "    (df_work, 'ts_begin'),\n",
    "    (df_work, 'ts_end'),\n",
    "    (df_stressors, 'timestamp'),\n",
    "    (df_hypo_event, 'timestamp'),\n",
    "    (df_illness, 'ts_begin'),\n",
    "    (df_illness, 'ts_end'),\n",
    "    (df_exercise, 'timestamp'),\n",
    "    (df_basis_heart_rate, 'timestamp'),\n",
    "    (df_basis_gsr, 'timestamp'),\n",
    "    (df_basis_skin_temp, 'timestamp'),\n",
    "    (df_basis_air_temp, 'timestamp'),\n",
    "    (df_basis_steps, 'timestamp'),\n",
    "    (df_basis_sleep, 'tbegin'),\n",
    "    (df_basis_sleep, 'tend')\n",
    "]\n",
    "\n",
    "# Loop through each dataframe and column pair to convert to datetime\n",
    "for df, col in datetime_columns:\n",
    "    if col in df.columns:  # Check if the column exists in the dataframe\n",
    "        df[col] = pd.to_datetime(df[col], dayfirst=True, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c883b02-88d4-48f2-9a46-fbe4ec8d65c8",
   "metadata": {},
   "source": [
    "#### 2. Check for null/missing values, and remove useless columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f13822be-f6c7-41ce-823b-32e547e93023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stressors = df_stressors.drop(['type', 'description'], axis=1)\n",
    "df_hypo_event = df_hypo_event.drop('symptom_name', axis=1)\n",
    "df_illness = df_illness.drop(['ts_end', 'type', 'description'], axis=1)\n",
    "df_exercise = df_exercise.drop(['type', 'competitive'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd10807-b26c-4245-96d4-44c0c4c5948d",
   "metadata": {},
   "source": [
    "#### 2.2 CGM data missing values handling.\n",
    "- interpolate if gap < 3hrs\n",
    "- fill with Nan if gap > 3hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d34ce0ac-08c8-4429-b449-0d3eaba9f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set timestamp as the index\n",
    "df_glucose.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Calculate the time difference between consecutive timestamps\n",
    "df_glucose['diff'] = df_glucose.index.to_series().diff()\n",
    "\n",
    "# Identify gaps longer than 3 hours\n",
    "# We need to handle cases where `diff` is NaT (e.g., for the first row)\n",
    "gaps = df_glucose[df_glucose['diff'].notna() & (df_glucose['diff'] > pd.Timedelta('3H'))]\n",
    "\n",
    "# Initialize lists to store new timestamps for both smaller and larger gaps\n",
    "new_timestamps = []\n",
    "\n",
    "# Generate new timestamps for gaps 3 hours or shorter\n",
    "for idx in df_glucose.index[1:]:\n",
    "    prev_time = df_glucose.index[df_glucose.index.get_loc(idx) - 1]\n",
    "    gap_duration = idx - prev_time\n",
    "    \n",
    "    if gap_duration <= pd.Timedelta('3H'):\n",
    "        # Generate timestamps for smaller gaps\n",
    "        new_times = pd.date_range(start=prev_time + pd.Timedelta('5T'), end=idx, freq='5T')\n",
    "        new_timestamps.extend(new_times)\n",
    "    else:\n",
    "        # Generate timestamps for larger gaps but don't fill them (NaN values will be preserved)\n",
    "        new_times = pd.date_range(start=prev_time + pd.Timedelta('5T'), end=idx, freq='5T')\n",
    "        new_timestamps.extend(new_times)\n",
    "\n",
    "# Remove duplicates and sort all timestamps\n",
    "new_timestamps = sorted(set(new_timestamps))\n",
    "\n",
    "# Reindex the DataFrame to include all new timestamps\n",
    "all_timestamps = sorted(set(df_glucose.index) | set(new_timestamps))\n",
    "df_glucose = df_glucose.reindex(all_timestamps)\n",
    "\n",
    "# Interpolate missing glucose values linearly for gaps 3 hours or shorter\n",
    "df_glucose['glucose'] = df_glucose['glucose'].interpolate(method='linear')\n",
    "\n",
    "# Round glucose values to one decimal place\n",
    "df_glucose['glucose'] = df_glucose['glucose'].round(0)\n",
    "\n",
    "# Drop the diff column\n",
    "df_glucose.drop(columns='diff', inplace=True)\n",
    "df_glucose.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb0c15-995c-4533-bc45-0da343ed2d27",
   "metadata": {},
   "source": [
    "#### 3. Create unified dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ff6d62-64de-4da1-845f-9948f8875604",
   "metadata": {},
   "source": [
    "##### 3.1 Merge temp basal and basal - override basal with temp basal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6d354c87-031a-41db-9502-7cc42db20cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine basal and temp basal rates = override the basal value with temp value\n",
    "\n",
    "# Step 1: Sort DataFrames\n",
    "df_basal.sort_values('timestamp', inplace=True)\n",
    "df_temp_basal.sort_values('ts_begin', inplace=True)\n",
    "\n",
    "# Step 2: Create a combined DataFrame\n",
    "df_comb_basal = df_basal.copy()\n",
    "\n",
    "# Step 3: Insert temp basal start and end times into the combined DataFrame\n",
    "for _, row in df_temp_basal.iterrows():\n",
    "    # Insert start time\n",
    "    df_comb_basal = pd.concat([\n",
    "        df_comb_basal,\n",
    "        pd.DataFrame({'timestamp': [row['ts_begin']], 'basal_rate': [row['temp_basal_rate']]})\n",
    "    ]).sort_values('timestamp').reset_index(drop=True)\n",
    "    \n",
    "    # Find the original basal rate before the temp basal period\n",
    "    if row['ts_end'] < df_basal['timestamp'].max():\n",
    "        previous_basal_value = df_basal[df_basal['timestamp'] <= row['ts_end']].iloc[-1]['basal_rate']\n",
    "    else:\n",
    "        previous_basal_value = df_basal[df_basal['timestamp'] <= row['ts_end']].iloc[-1]['basal_rate']\n",
    "    \n",
    "    # Insert end time with the original basal rate\n",
    "    df_comb_basal = pd.concat([\n",
    "        df_comb_basal,\n",
    "        pd.DataFrame({'timestamp': [row['ts_end']], 'basal_rate': [previous_basal_value]})\n",
    "    ]).sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# Step 4: Interpolate missing values if necessary (optional, based on your needs)\n",
    "df_comb_basal.set_index('timestamp', inplace=True)\n",
    "df_comb_basal['basal_rate'].interpolate(method='linear', inplace=True)  # dont need to if checked for null before and handled \n",
    "df_comb_basal.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b18bb4-47cd-488d-bb99-428d01f7e638",
   "metadata": {},
   "source": [
    "##### 3.2 Merge with glucose - resample basal to 5 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "08a07439-a7e0-425d-b2e5-565379d2d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge glucose and basal variables = resample to 5 minutes interval to match CGM data\n",
    "\n",
    "# Step 1: Convert timestamps to index for each dataframe\n",
    "df_glucose.set_index('timestamp', inplace=True)\n",
    "df_comb_basal.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Step 2: Merge the dataframes, using the closest earlier basal value for each glucose timestamp\n",
    "df_glucose_basal = pd.merge_asof(df_glucose, df_comb_basal, on='timestamp', direction='backward')\n",
    "\n",
    "# Step 3: Reset index if necessary\n",
    "df_glucose_basal.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6a5669-f852-4827-a894-64cb57e39f44",
   "metadata": {},
   "source": [
    "#### 3.3 Merge with sleep - aggregate by date and assign to all "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be89944c-11bf-448d-b5eb-442f9fd6b5e6",
   "metadata": {},
   "source": [
    "#### Check and fix if sleep times are reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9cd3ff9f-945c-45ec-8d11-dc5fe7e6fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap the timestamps where ts_begin is after ts_end\n",
    "df_sleep.loc[df_sleep['ts_begin'] > df_sleep['ts_end'], ['ts_begin', 'ts_end']] = \\\n",
    "    df_sleep.loc[df_sleep['ts_begin'] > df_sleep['ts_end'], ['ts_end', 'ts_begin']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00954e3b-52a2-44f5-a9c6-455a885f44ae",
   "metadata": {},
   "source": [
    "#### Calculate sleep duration and aggregate by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "08d68160-f07d-4be6-874a-dbea5b76d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caculate sleep duration in hours\n",
    "df_sleep['sleep_duration_hours'] = (df_sleep['ts_end'] - df_sleep['ts_begin']).dt.total_seconds() / 3600\n",
    "df_sleep['sleep_duration_hours'] = df_sleep['sleep_duration_hours'].round(1)\n",
    "\n",
    "# Extract date and aggregate sleep duration by date\n",
    "df_sleep['date'] = df_sleep['ts_begin'].dt.date\n",
    "df_sleep_aggregated = df_sleep.groupby('date')['sleep_duration_hours'].sum().reset_index()\n",
    "\n",
    "# Concatenate the two dataframes\n",
    "df_combined = pd.DataFrame()\n",
    "\n",
    "# Add a date column to the combined dataframe\n",
    "df_glucose_basal['date'] = df_glucose_basal['timestamp'].dt.date\n",
    "\n",
    "# Merge the aggregated sleep data with the combined dataframe\n",
    "df_combined = pd.merge(df_glucose_basal, df_sleep_aggregated, on='date', how='right')\n",
    "\n",
    "# Drop the intermediate date column if no longer needed\n",
    "df_combined.drop(columns='date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45f7a64-c953-488a-bf27-2e417a183eb5",
   "metadata": {},
   "source": [
    "##### 4.4 Merge with bolus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d9d1f267-8590-4d46-bf2d-1245e7760ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename ts_begin to timestamp to match with df_glucose_basal\n",
    "df_bolus['bolus_duration_mins'] = (df_bolus['ts_end'] - df_bolus['ts_begin']).dt.total_seconds() / 60.0\n",
    "\n",
    "# Drop ts_end since we have duration now\n",
    "df_bolus.drop(columns=['ts_end'], inplace=True)\n",
    "\n",
    "# Rename to match format of combined dataframe\n",
    "df_bolus.rename(columns={'ts_begin': 'timestamp', 'type':'bolus_type', 'dose' : 'bolus_dose'}, inplace=True)\n",
    "\n",
    "# Concatenate the two dataframes\n",
    "df_combined = pd.concat([df_combined, df_bolus], ignore_index=True)\n",
    "\n",
    "# Sort by timestamp to maintain chronological order\n",
    "df_combined.sort_values(by='timestamp', inplace=True)\n",
    "\n",
    "# Reset the index\n",
    "df_combined.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c20fdc8-b3be-4b12-b872-2af07dcee563",
   "metadata": {},
   "source": [
    "##### 4.4 Merge with meal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2050d329-6a0b-4a12-b044-6d3925ba574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge meal data with the combined DataFrame\n",
    "df_combined = pd.concat([df_combined, df_meal[['timestamp', 'meal_type', 'carbs']]], sort=False)\n",
    "\n",
    "# Sort by timestamp to maintain chronological order\n",
    "df_combined.sort_values(by='timestamp', inplace=True)\n",
    "\n",
    "# Optional: reset index if needed\n",
    "df_combined.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7192a4d5-8019-4dee-a43e-2d8e19e75371",
   "metadata": {},
   "source": [
    "##### 4.4 Merge with exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ca1a0f55-ddc5-4075-a17f-cd1587a7ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exercise.rename(columns={'intensity': 'exercise_intensity', 'duration':'exercise_duration_mins'}, inplace=True)\n",
    "\n",
    "# Merge exercise data with the combined DataFrame\n",
    "df_combined = pd.concat([df_combined, df_exercise[['timestamp', 'exercise_intensity', 'exercise_duration_mins']]], sort=False)\n",
    "\n",
    "# Sort by timestamp to maintain chronological order\n",
    "df_combined.sort_values(by='timestamp', inplace=True)\n",
    "\n",
    "# Optional: reset index if needed\n",
    "df_combined.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ff664-57b5-4a45-9d58-4c1c51bd9811",
   "metadata": {},
   "source": [
    "#### 5. Forward/backward fill continous values + create flags for events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5b763a96-9707-4f7b-945d-d0530c1c0faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[['glucose', 'basal_rate', 'sleep_duration_hours']] = df_combined[['glucose', 'basal_rate', 'sleep_duration_hours']].ffill().bfill()\n",
    "df_combined['bolus_flag'] = df_combined['bolus_dose'].notnull().astype(int)\n",
    "df_combined['meal_flag'] = df_combined['carbs'].notnull().astype(int)\n",
    "df_combined['exercise_flag'] = df_combined['exercise_duration_mins'].notnull().astype(int)\n",
    "df_combined['bolus_dose'].fillna(0, inplace=True)\n",
    "df_combined['carbs'].fillna(0, inplace=True)\n",
    "df_combined['exercise_duration_mins'].fillna(0, inplace=True)\n",
    "df_combined['bolus_duration_mins'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6217acf2-028c-4cc5-9eae-8c7c6f2de58c",
   "metadata": {},
   "source": [
    "#### 6. Extract hour from timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "84bb73a5-908f-4781-97f0-4c91e95c3ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['hour_of_day'] = df_combined['timestamp'].dt.hour # feature engineering   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7110bea4-19b3-48eb-901b-c67f13f4131a",
   "metadata": {},
   "source": [
    "#### 7. Examine dataframe and remove unnecessary features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6082f37a-e76c-422f-9968-fc7269c37071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined.drop(columns=['bolus_type', 'exercise_intensity' ,'meal_type', 'carb_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9073f114-d24e-4514-ab98-63a6f631d64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12408 entries, 0 to 12407\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   Timestamp                 12408 non-null  datetime64[ns]\n",
      " 1   Glucose (mg/dL)           12408 non-null  float64       \n",
      " 2   Basal Rate (U/h)          12408 non-null  float64       \n",
      " 3   Sleep Duration (Hrs)      12408 non-null  float64       \n",
      " 4   Bolus Dose (U)            12408 non-null  float64       \n",
      " 5   Bolus Duration (Mins)     12408 non-null  float64       \n",
      " 6   Carbs (Grams)             12408 non-null  float64       \n",
      " 7   Exercise Duration (Mins)  12408 non-null  float64       \n",
      " 8   Bolus Flag                12408 non-null  int64         \n",
      " 9   Meal Flag                 12408 non-null  int64         \n",
      " 10  Exercise Flag             12408 non-null  int64         \n",
      " 11  Hour Of Day               12408 non-null  int32         \n",
      "dtypes: datetime64[ns](1), float64(7), int32(1), int64(3)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary to rename your columns\n",
    "new_column_names = {\n",
    "    'timestamp': 'Timestamp',\n",
    "    'glucose': 'Glucose (mg/dL)',\n",
    "    'basal_rate': 'Basal Rate (U/h)',\n",
    "    'sleep_duration_hours': 'Sleep Duration (Hrs)',\n",
    "    'bolus_dose': 'Bolus Dose (U)',\n",
    "    'bolus_duration_mins': 'Bolus Duration (Mins)',\n",
    "    'carbs': 'Carbs (Grams)',\n",
    "    'exercise_duration_mins': 'Exercise Duration (Mins)',\n",
    "    'bolus_flag': 'Bolus Flag',\n",
    "    'meal_flag': 'Meal Flag',\n",
    "    'exercise_flag': 'Exercise Flag',\n",
    "    'hour_of_day': 'Hour Of Day'\n",
    "}\n",
    "\n",
    "# Renaming the columns in the DataFrame\n",
    "df_combined.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame with the new column names\n",
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e12c9d4-517d-4292-9346-dcc8a1944e81",
   "metadata": {},
   "source": [
    "#### 8. Save as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "81a860c3-da6c-46b3-aa8e-cdd0c635a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to a CSV file\n",
    "df_combined.to_csv('path-to-save-file.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
